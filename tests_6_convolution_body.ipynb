{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from Lineaire.Linear import *\n",
    "from Loss.BCELoss import BCELoss\n",
    "from Activation.Tanh import Tanh\n",
    "from Activation.Sigmoide import Sigmoide\n",
    "from Activation.ReLu import ReLU\n",
    "from Encapsulation.AutoEncodeur import AutoEncodeur\n",
    "from Encapsulation.Sequentiel import Sequentiel\n",
    "from Encapsulation.Optim import SGD\n",
    "from Activation.SoftMax import  SoftMax\n",
    "from Loss.CELogSoftMax import CELogSoftMax\n",
    "from Loss.CELoss import CELoss\n",
    "\n",
    "from convolution import *\n",
    "\n",
    "from utils import tools\n",
    "from Encapsulation import fonctions as fn\n",
    "\n",
    "from icecream import ic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def onehot(y):\n",
    "    onehot = np.zeros((y.size,y.max()+1))\n",
    "    onehot[np.arange(y.size),y]=1\n",
    "    return onehot\n",
    "\n",
    "# Load Data From USPS , directement pris depuis TME4\n",
    "uspsdatatrain = \"C:/_TME\\Projet-ML/dataset/USPS_train.txt\"\n",
    "uspsdatatest = \"C:/_TME\\Projet-ML/dataset/USPS_test.txt\" \n",
    "\n",
    "alltrainx, alltrainy = tools.load_usps(uspsdatatrain)\n",
    "alltestx, alltesty = tools.load_usps(uspsdatatest)\n",
    "alltrainx, alltrainy = alltrainx[:1000],alltrainy[:1000]\n",
    "alltestx, alltesty = alltestx[:500],alltesty[:500]\n",
    "# taille couche\n",
    "input = len(alltrainx[0])\n",
    "out = len(np.unique(alltesty))\n",
    "alltrainy = onehot(alltrainy)\n",
    "alltesty= onehot(alltesty)\n",
    "alltrainx = alltrainx.reshape(alltrainx.shape[0], alltrainx.shape[1], 1)\n",
    "alltestx = alltestx.reshape(alltestx.shape[0], alltestx.shape[1], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    #retourner la meuilleur classe\n",
    "    return np.argmax(x,axis=1)\n",
    "\n",
    "#score = []\n",
    "iteration = 25\n",
    "gradient_step = 1e-4\n",
    "batch_size = 100\n",
    "\n",
    "net = Sequentiel(*[Conv1D(3, 1, 32, stride=1),\n",
    "                      MaxPool1D(2, 2),\n",
    "                      Flatten(),\n",
    "                      Linear(4064, 100, init_type=1),\n",
    "                      ReLU(),\n",
    "                      Linear(100, 10,init_type=1),\n",
    "                      SoftMax()\n",
    "                        ]) #,label=pred\n",
    "\n",
    "loss_ce = CELoss()   \n",
    "\n",
    "net, couts, opt = SGD(net, alltrainx, alltrainy, nb_batch=50, loss=loss_ce, nb_epochs=iteration,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(couts)),couts,color='red',label=\"la function de cout\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.title(\"variation de la fonction de cout\")\n",
    "plt.savefig(\"loss_convolution.png\")\n",
    "#plt.show()\n",
    "\n",
    "# SGD(net, X_train_scaled, X_train_scaled,nb_batch=10, loss=loss_bce, nb_epochs=iter, eps=1e-1, shuffle=True)\n",
    "#############################\n",
    "\n",
    "# with open('net_trained.pkl', 'wb') as f:\n",
    "#     pickle.dump(net, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "\n",
    "# alltrainx, alltrainy = tools.load_usps(uspsdatatrain)\n",
    "# alltestx, alltesty = tools.load_usps(uspsdatatest)\n",
    "# alltrainx, alltrainy = alltrainx[:5000],alltrainy[:5000]\n",
    "# alltestx, alltesty = alltestx[:5000],alltesty[:5000]\n",
    "# alltrainx = alltrainx.reshape(alltrainx.shape[0], alltrainx.shape[1], 1)\n",
    "# alltestx = alltestx.reshape(alltestx.shape[0], alltestx.shape[1], 1)\n",
    "\n",
    "# with open('net_trained.pkl', 'rb') as f:\n",
    "#     net=pickle.load(f)\n",
    "\n",
    "# # ic(alltrainx.shape)\n",
    "# # ic(alltrainy.shape)\n",
    "del opt\n",
    "\n",
    "_, alltrainy = tools.load_usps(uspsdatatrain)\n",
    "_, alltesty = tools.load_usps(uspsdatatest)\n",
    "\n",
    "alltrainy = alltrainy[:1000]\n",
    "alltesty = alltesty[:500]\n",
    "\n",
    "predict = net.forward(alltrainx)\n",
    "# print((np.where(predict == alltrainy, 1, 0)).mean() )\n",
    "score_train = fn.score(alltrainy,predict)\n",
    "print(\"Le score d'accuracy en train = \", score_train)\n",
    "\n",
    "predict = net.forward(alltestx)\n",
    "score_test = fn.score(alltesty,predict)\n",
    "print(\"Le score d'accuracy en train = \", score_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
